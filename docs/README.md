# üìö Documenta√ß√£o T√©cnica - Comparador de Modelos de RI

Documenta√ß√£o completa para desenvolvedores sobre instala√ß√£o, arquitetura, desenvolvimento e detalhes t√©cnicos do projeto.

---

## üìã √çndice

- [Instala√ß√£o](#-instala√ß√£o)
- [Configura√ß√£o](#-configura√ß√£o)
- [Arquitetura](#-arquitetura)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Como Funciona](#-como-funciona)
- [Conceitos T√©cnicos](#-conceitos-t√©cnicos)
- [Desenvolvimento](#-desenvolvimento)
- [API Reference](#-api-reference)
- [Troubleshooting](#-troubleshooting)

---

## üöÄ Instala√ß√£o

### Pr√©-requisitos

- **Python 3.11+** (recomendado usar Conda)
- **Node.js 18+** e npm/pnpm
- **Git**

### Backend (Python)

#### 0. Git Clone

```bash
git clone https://github.com/dev-jonathan/simple-search-rank
cd simple-search-rank
```

#### 1. Criar ambiente Conda

```bash
# Na raiz do projeto
conda create -n search-rank python=3.11 -y
conda activate search-rank
```

#### 2. Instalar depend√™ncias Python

```bash
cd backend
pip install -r requirements.txt
```

#### 3. Baixar modelos NLP

```bash
# Modelo spaCy para portugu√™s
python -m spacy download pt_core_news_md
# Ou baixe manualmente https://github.com/explosion/spacy-models/releases/download/pt_core_news_md-3.8.0/pt_core_news_md-3.8.0.tar.gz

# Dados NLTK (RSLP stemmer)
python -c "import nltk; nltk.download('rslp')"
```

#### 4. Configurar vari√°veis de ambiente

```bash
# Criar .env na raiz ou backend/
echo "DOWNLOAD_PDFS=true" > .env  # Para desenvolvimento local
```

**Vari√°veis dispon√≠veis:**
- `DOWNLOAD_PDFS`: `true` para baixar PDFs automaticamente do GitHub, `false` para usar apenas cache
- `CORPUS_PATH`: Caminho customizado para o corpus (opcional)

#### 5. (Alternativa) Ou use Docker

```bash
cd backend
docker build -t search-rank-api .
docker images
docker run -p 8000:8000 -e DOWNLOAD_PDFS=false -e CORPUS_PATH=/app/pdf_dataset search-rank-api
docker logs -f search-rank-api
```
### Frontend (Next.js)

```bash
# Na raiz do projeto
npm install
# ou
pnpm install
```

---

## ‚öôÔ∏è Configura√ß√£o

### Modo Desenvolvimento

```bash
# .env
DOWNLOAD_PDFS=true
```

O sistema baixar√° automaticamente os PDFs do GitHub na primeira inicializa√ß√£o.

### Modo Produ√ß√£o

```bash
# .env
DOWNLOAD_PDFS=false
```

O sistema usar√° apenas o cache versionado (j√° processado), sem necessidade dos PDFs.

### Reposit√≥rio dos PDFs

Os PDFs est√£o hospedados em: [wiki-popular-articles-to-pdf](https://github.com/dev-jonathan/wiki-popular-articles-to-pdf/tree/main/pdf_dataset)

O script `backend/scripts/download_pdfs.py` baixa automaticamente quando `DOWNLOAD_PDFS=true`.

---

## üèóÔ∏è Arquitetura

### Vis√£o Geral

```
Frontend (Next.js) ‚Üí API REST (FastAPI) ‚Üí Servi√ßos de Processamento ‚Üí Retorno JSON
     ‚Üì                      ‚Üì                        ‚Üì
  React UI          FastAPI Endpoints      TF-IDF / BM25 Models
```

### Fluxo de Dados

1. **Usu√°rio** digita busca no frontend
2. **Frontend** envia requisi√ß√£o POST para `/api/search`
3. **Backend** processa query e executa TF-IDF e BM25 em paralelo
4. **Backend** retorna resultados ordenados com m√©tricas
5. **Frontend** exibe resultados lado a lado com gr√°ficos

---

## üìÅ Estrutura do Projeto

```
simple-search-rank/
‚îú‚îÄ‚îÄ app/                      # Frontend Next.js
‚îÇ   ‚îú‚îÄ‚îÄ page.tsx             # P√°gina principal
‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx           # Layout global
‚îÇ   ‚îî‚îÄ‚îÄ globals.css          # Estilos globais
‚îÇ
‚îú‚îÄ‚îÄ components/               # Componentes React
‚îÇ   ‚îú‚îÄ‚îÄ header.tsx           # Cabe√ßalho
‚îÇ   ‚îú‚îÄ‚îÄ control-panel.tsx   # Painel de controle
‚îÇ   ‚îú‚îÄ‚îÄ results-display.tsx # Exibi√ß√£o de resultados
‚îÇ   ‚îú‚îÄ‚îÄ metrics-panel.tsx   # Dashboard de m√©tricas
‚îÇ   ‚îî‚îÄ‚îÄ ui/                  # Componentes UI (shadcn)
‚îÇ
‚îú‚îÄ‚îÄ lib/                      # Utilit√°rios frontend
‚îÇ   ‚îú‚îÄ‚îÄ api.ts               # Cliente API
‚îÇ   ‚îú‚îÄ‚îÄ types.ts             # Tipos TypeScript
‚îÇ   ‚îî‚îÄ‚îÄ utils.ts             # Fun√ß√µes auxiliares
‚îÇ
‚îú‚îÄ‚îÄ backend/                  # Backend FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py          # Entry point FastAPI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py        # Configura√ß√µes
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ search.py    # POST /api/search
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ corpus.py     # GET /api/corpus/*
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py       # Modelos Pydantic
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search_service.py    # Orquestra TF-IDF e BM25
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tfidf_service.py     # Implementa√ß√£o TF-IDF
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bm25_service.py      # Implementa√ß√£o BM25
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py     # NLP (lematiza√ß√£o, stemiza√ß√£o)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdf_parser.py        # Extra√ß√£o de texto de PDFs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ corpus_manager.py    # Gerenciamento do corpus
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cache_service.py     # Sistema de cache
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ text_processing.py   # Utilit√°rios de texto
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ constants.py         # Constantes
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ download_pdfs.py         # Script para baixar PDFs
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ cache/                # Cache processado (versionado)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ documents.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ texts.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ processed_terms.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ corpus_hash.json
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ public/                   # Assets est√°ticos
‚îÇ   ‚îú‚îÄ‚îÄ interface_inicial.png
‚îÇ   ‚îî‚îÄ‚îÄ interface_plots.png
‚îÇ
‚îú‚îÄ‚îÄ docs/                     # Documenta√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ README.md            # Este arquivo
‚îÇ   ‚îî‚îÄ‚îÄ TODO.md              # Ideias futuras
‚îÇ
‚îî‚îÄ‚îÄ package.json             # Depend√™ncias frontend
```

---

## üîß Como Funciona

### Sistema de Cache

O projeto utiliza um sistema de cache inteligente para otimizar performance:

#### ‚úÖ Versionado no Git (~20MB)
- `backend/cache/documents.json` - Metadados dos documentos
- `backend/cache/texts.json` - Textos completos extra√≠dos
- `backend/cache/processed_terms.json` - Termos processados com frequ√™ncias
- `backend/cache/corpus_hash.json` - Hashes SHA256 dos PDFs

#### ‚ùå N√£o Versionado (~130MB)
- `backend/pdf_dataset/` - PDFs originais (baixados automaticamente)

#### Como Funciona

1. **Primeira Execu√ß√£o**:
   - Sistema processa todos os PDFs
   - Extrai texto, processa termos, calcula hashes
   - Salva tudo em JSON no cache

2. **Execu√ß√µes Subsequentes**:
   - Sistema verifica se cache existe e √© v√°lido
   - Compara hashes dos PDFs com cache salvo
   - Se v√°lido: carrega do cache (muito r√°pido!)
   - Se inv√°lido: reprocessa e atualiza cache

3. **Invalida√ß√£o Autom√°tica**:
   - PDF adicionado/removido
   - PDF modificado (hash diferente)

#### Performance

- **Sem cache**: ~2-5 minutos processando 97 PDFs
- **Com cache**: ~5-15 segundos carregando do JSON

### Processamento de Texto

1. **Extra√ß√£o**: `pdf_parser.py` extrai texto dos PDFs
2. **Limpeza**: Remove caracteres especiais, normaliza
3. **Lematiza√ß√£o**: spaCy (`pt_core_news_md`) converte palavras para forma base
4. **Stemiza√ß√£o**: NLTK RSLP para portugu√™s
5. **Stopwords**: Remove palavras comuns sem significado
6. **Indexa√ß√£o**: Cria √≠ndice de termos com frequ√™ncias

### Modelos de Busca

#### TF-IDF (Modelo Vetorial)

- **TF (Term Frequency)**: `1 + log10(frequ√™ncia)` - Frequ√™ncia do termo no documento
- **IDF (Inverse Document Frequency)**: `log10(1 + N / df)` - Raridade do termo na cole√ß√£o
- **TF-IDF**: `TF * IDF` - Combina import√¢ncia local e global
- **Similaridade**: Cosseno entre vetores normalizados

**Caracter√≠sticas:**
- Representa documentos como vetores multidimensionais
- Normaliza por tamanho do vetor
- Para queries com 1 termo: usa TF-IDF bruto (n√£o normalizado) para diferenciar documentos

#### BM25 (Modelo Probabil√≠stico)

- **F√≥rmula**: Baseada em probabilidades de relev√¢ncia
- **Par√¢metros**:
  - `k1`: Satura√ß√£o de frequ√™ncia (padr√£o: 1.2)
  - `b`: Normaliza√ß√£o por tamanho (padr√£o: 0.75)

**Caracter√≠sticas:**
- Considera satura√ß√£o de frequ√™ncia (evita dom√≠nio de termos muito frequentes)
- Normaliza por tamanho do documento
- Geralmente mais eficaz que TF-IDF para busca

---

## üíª Desenvolvimento

### Rodar o Backend

```bash
conda activate search-rank
cd backend
uvicorn app.main:app --reload --port 8000
```

A API estar√° dispon√≠vel em:
- **API**: http://localhost:8000
- **Docs**: http://localhost:8000/docs (Swagger UI)
- **Health**: http://localhost:8000/health

### Rodar o Frontend

```bash
npm run dev
# ou
pnpm dev
```

Acesse: http://localhost:3000

### Comandos √öteis

#### Baixar PDFs manualmente
```bash
cd backend
python scripts/download_pdfs.py
```

#### Limpar cache (for√ßar reprocessamento)
```bash
cd backend
rm -rf cache/*.json
# Reiniciar servidor com DOWNLOAD_PDFS=true
```

#### Verificar status do cache
```bash
ls -lh backend/cache/
```

---

## üì° API Reference

### `POST /api/search`

Realiza busca usando TF-IDF e BM25.

**Request:**
```json
{
  "query": "adele",
  "k1": 1.2,
  "b": 0.75,
  "tfIdfWeight": "log",
  "topK": null
}
```

**Response:**
```json
{
  "tfidf": [
    {
      "id": "doc_1",
      "title": "Adele",
      "score": 5.4155,
      "snippet": "...texto relevante...",
      "matchedWords": ["adele"],
      "filename": "Adele.pdf"
    }
  ],
  "bm25": [...],
  "metrics": {
    "preprocessTime": 7.9,
    "tfidfTime": 17.5,
    "bm25Time": 16.0
  }
}
```

### `GET /api/corpus/info`

Retorna estat√≠sticas do corpus.

**Response:**
```json
{
  "total_documents": 97,
  "total_terms": 72587,
  "avg_doc_length": 1500
}
```

### `GET /api/corpus/list`

Lista todos os documentos do corpus.

**Response:**
```json
{
  "documents": [
    {"id": "doc_1", "title": "Adele"},
    {"id": "doc_2", "title": "Brasil"},
    ...
  ]
}
```

### `GET /api/corpus/pdf/{doc_id}`

Retorna o arquivo PDF de um documento (redireciona para GitHub).

---

## üîç Conceitos T√©cnicos

### TF-IDF (Term Frequency-Inverse Document Frequency)

**Componentes:**

1. **TF (Term Frequency)**: `TF = 1 + log10(frequ√™ncia)`
   - Quanto mais vezes a palavra aparece, maior o TF
   - Log atenua impacto de palavras muito frequentes

2. **IDF (Inverse Document Frequency)**: `IDF = log10(1 + N / df)`
   - `N` = total de documentos
   - `df` = n√∫mero de documentos que cont√™m o termo
   - Quanto mais raro o termo, maior o IDF

3. **TF-IDF**: `TF * IDF`
   - Combina import√¢ncia local (TF) com import√¢ncia global (IDF)

### Similaridade do Cosseno

- Mede o √¢ngulo entre dois vetores
- F√≥rmula: `similaridade = (vetor_A ¬∑ vetor_B) / (norma_A * norma_B)`
- Valores: de -1 (opostos) a 1 (id√™nticos)
- **Problema com 1 termo**: Todos os documentos t√™m similaridade = 1.0 (solu√ß√£o: usar TF-IDF bruto)

### BM25

- Modelo probabil√≠stico que estima relev√¢ncia
- Considera satura√ß√£o de frequ√™ncia (k1) e normaliza√ß√£o por tamanho (b)
- F√≥rmula mais complexa, geralmente mais eficaz que TF-IDF

### Norma (Norm)

- Tamanho/magnitude de um vetor
- Norma L2: `sqrt(soma dos quadrados dos valores)`
- Usada para normalizar vetores (tamanho = 1)

---

## üêõ Troubleshooting

### Problema: Cache n√£o encontrado

**Solu√ß√£o:**
```bash
# Habilitar download autom√°tico
echo "DOWNLOAD_PDFS=true" > .env
# Reiniciar servidor
```

### Problema: Similaridade TF-IDF sempre 1.0

**Causa**: Query com apenas 1 termo em corpus pequeno

**Solu√ß√£o**: Sistema j√° corrigido para usar TF-IDF bruto quando h√° 1 termo

### Problema: Poucos resultados retornados

**Causa**: Limite padr√£o de `top_k`

**Solu√ß√£o**: Passar `topK` na requisi√ß√£o ou aumentar limite padr√£o

### Problema: Erro ao baixar PDFs

**Solu√ß√£o:**
- Verificar conex√£o com internet
- Verificar se reposit√≥rio GitHub est√° acess√≠vel
- Baixar manualmente: `python backend/scripts/download_pdfs.py`

### Problema: Erro ao processar PDFs

**Solu√ß√£o:**
- Verificar se PDFs n√£o est√£o corrompidos
- Verificar logs do servidor para detalhes
- Limpar cache e reprocessar

---

## üìä Performance

### Tempos T√≠picos

- **Carregamento do cache**: ~5-15 segundos
- **Processamento inicial**: ~2-5 minutos (97 PDFs)
- **Busca TF-IDF**: ~10-20ms
- **Busca BM25**: ~10-20ms
- **Pr√©-processamento**: ~5-10ms

### Otimiza√ß√µes Implementadas

1. **Cache de √≠ndices**: TF-IDF e BM25 calculados uma vez na inicializa√ß√£o
2. **Processamento paralelo**: TF-IDF e BM25 executam simultaneamente
3. **Cache de documentos**: Textos processados salvos em JSON
4. **Valida√ß√£o de hash**: Detecta mudan√ßas automaticamente

---

## üéØ Decis√µes T√©cnicas

### Armazenamento
- **Mem√≥ria** (sem banco de dados)
- Simples para experimental
- R√°pido (sem I/O)
- Suficiente para 97-200 documentos

### Parser de PDFs
- **pdfplumber**: Leve, r√°pido, suficiente para PDFs de texto simples
- Alternativa futura: docling (se necess√°rio para PDFs complexos)

### Processamento de Texto
- **spaCy**: Lematiza√ß√£o e tokeniza√ß√£o
- **NLTK RSLP**: Stemiza√ß√£o para portugu√™s
- **Stopwords customizadas**: Lista otimizada

### Reposit√≥rio Otimizado
- Cache versionado (~20MB) no Git
- PDFs n√£o versionados (baixados automaticamente)
- Setup r√°pido em produ√ß√£o

---

## üìù Notas Importantes

- **Corpus fixo**: 97 artigos da Wikipedia em portugu√™s
- **Sem banco de dados**: Armazenamento em mem√≥ria
- **Cache descart√°vel**: Pode limpar a qualquer momento
- **Portfolio/Educacional**: Foco em demonstra√ß√£o e aprendizado

---

Para ideias futuras e melhorias, consulte as issues.

